{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>kache is a modern cloud-native web accelerator and HTTP cache proxy that is highly available, reliable, and performant. It supports the latest RFC specifications and should be able to handle high traffic loads, be easily scalable, and support distributed caching systems.</p>"},{"location":"getting-started/","title":"Getting started","text":""},{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) 2023 kache.io</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"support/","title":"Sponsors","text":"<p>kache is sponsored and supported by Media Tech Lab.</p> <p> </p>"},{"location":"blog/","title":"Blog","text":""},{"location":"intro/installation/","title":"Installation","text":"<p>You can install and run Kache in the following ways:</p> <ul> <li>Use the official Docker image</li> <li>Use the binary distribution</li> <li>Build binary from source</li> <li>Use the Helm Chart</li> </ul>"},{"location":"intro/installation/#use-the-official-docker-image","title":"Use the Official Docker Image","text":"<p>Use one of the official Docker images and run it with the sample configuration file:</p> <pre><code>docker run -d -p 8080:8080 -p 80:80 \\\n    -v $PWD/kache.yml:/etc/kache/kache.yml \\\n    kache:latest -config.file=/etc/kache/kache.yml \n</code></pre>"},{"location":"intro/installation/#use-the-binary-distribution","title":"Use the binary distribution","text":"<p>To run kache, get the latest binary from the releases page and run it with the sample configuration file:</p> <pre><code>./kache -config.file=kache.yml\n</code></pre>"},{"location":"intro/installation/#build-binary-from-source","title":"Build binary from source","text":"<pre><code>git clone https://github.com/kacheio/kache\n</code></pre>"},{"location":"intro/installation/#use-the-helm-chart","title":"Use the Helm Chart","text":"<p>Info</p> <p>Comming soon!</p>"},{"location":"intro/installation/#quick-start","title":"Quick Start","text":"<p>If you want to run kache with a distributed caching backend (e.g. Redis), you can use and run this example docker-compose as a starting point:</p> <pre><code>docker-compose -f cloud/docker-compose.yml up \n</code></pre> <p>Tip</p> <p>Check the Quick Starts for Docker and Kubernetes to learn more.</p>"},{"location":"intro/quick-start-k8s/","title":"Kache on Kubernetes","text":"<p>The following describes how to run kache on a local Kubernetes cluster.</p> <p>Warning</p> <p>Please note that this is not intended for use in a production environment. We will provide more sophisticated configurations for operations in the future. </p>"},{"location":"intro/quick-start-k8s/#start-a-kubernetes-cluster","title":"Start a Kubernetes cluster","text":"<p>To start a cluster, use minikube or Docker Desktop.</p> <pre><code>minikube start\n</code></pre>"},{"location":"intro/quick-start-k8s/#deploy-configmap","title":"Deploy ConfigMap","text":"<p>Create a ConfigMap that contains the kache configuration:</p> <pre><code>kubectl create configmap kache-config --from-file=cloud/kubernetes/configmap.yml </code></pre> <p>Apply the ConfigMap:</p> <pre><code>kubectl apply -f cloud/kubernetes/configmap.yml\n</code></pre> configmap.yml Kubernetes <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\nname: kache-config\ndata:\nconfig.yml: |-\nlisteners:\nweb1:\naddr: :80\nweb2:\naddr: :1337\nupstreams:\n- name: service1\naddr: \"http://localhost:8000\"\npath: \"/service/1\"\n- name: service2\naddr: \"http://example.com\"\npath: \"/\"\napi:\nport: 1338\ndebug: true\nlogging:\nlevel: debug\nprovider:\nbackend: redis\nredis:\nendpoint: \"redis-master:6379\"\nusername:\npassword:\ndb:\n</code></pre>"},{"location":"intro/quick-start-k8s/#deploy-redis","title":"Deploy Redis","text":"<pre><code>kubectl apply -f cloud/kubernetes/redis-master.yml\n</code></pre> redis.yml Kubernetes <pre><code>---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: redis-master\nlabels:\napp: redis\nspec:\nselector:\nmatchLabels:\napp: redis\nrole: master\ntier: backend\nreplicas: 1\ntemplate:\nmetadata:\nlabels:\napp: redis\nrole: master\ntier: backend\nspec:\ncontainers:\n- name: master\nimage: redis\nresources:\nrequests:\ncpu: 100m\nmemory: 100Mi\nports:\n- containerPort: 6379\n---\napiVersion: v1\nkind: Service\nmetadata:\nname: redis-master\nlabels:\napp: redis\nrole: master\ntier: backend\nspec:\nports:\n- port: 6379\ntargetPort: 6379\nselector:\napp: redis\nrole: master\ntier: backend\n</code></pre>"},{"location":"intro/quick-start-k8s/#deploy-kache","title":"Deploy Kache","text":"<pre><code>kubectl apply -f cloud/kubernetes/kache.yml\n</code></pre> kache.yml Kubernetes <pre><code>---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: kache\nspec:\nreplicas: 1\nselector:\nmatchLabels:\napp: kache\ntemplate:\nmetadata:\nlabels:\napp: kache\nspec:\ncontainers:\n- name: kache\nimage: kacheio/kache:main\nimagePullPolicy: Always\nargs:\n- \"-config.file=/etc/kache/config.yml\"\nenv:\n- name: NAMESPACE\nvalueFrom:\nfieldRef:\nfieldPath: metadata.namespace\nvolumeMounts:\n- name: config\nmountPath: /etc/kache\nports:\n- containerPort: 8080\nname: http\n- containerPort: 1337\nname: web\n- containerPort: 1338\nname: api\nresources:\nrequests:\ncpu: 100m\nmemory: 100Mi\nvolumes:\n- name: config\nconfigMap:\nname: kache-config\n---\napiVersion: v1\nkind: Service\nmetadata:\nname: kache-service\nlabels:\napp: kache\nspec:\ntype: LoadBalancer\nports:\n- name: \"http\"\nport: 80\ntargetPort: http\n- name: \"web\"\nport: 1337\ntargetPort: web\n- name: \"api\"\nport: 1338\ntargetPort: api\nselector:\napp: kache\n</code></pre>"},{"location":"intro/quick-start-k8s/#accessing-the-service","title":"Accessing the service","text":"<p>Check that the Pods are up and running:</p> <pre><code>$ kubectl get pods NAME                           READY   STATUS    RESTARTS   AGE\nkache-54cd8ffd96-xzdqg         1/1     Running   0          14h\nredis-master-d4f785667-mpmvg   1/1     Running   0          14h\n</code></pre> <p>The Kache service is exposed as a LoadBalancer via the service with mapped ports and is accessible on localhost.</p> <pre><code>$ kubectl get svc\n\nNAME            TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)                                      AGE\nkache-service   LoadBalancer   10.110.92.73   localhost     80:30135/TCP,1337:32284/TCP,1338:30691/TCP   44h\nkubernetes      ClusterIP      10.96.0.1      &lt;none&gt;        443/TCP                                      44h\nredis-master    ClusterIP      10.97.188.34   &lt;none&gt;        6379/TCP                                     44h\n</code></pre> <p>Use the above endpoints to access the service:</p> <pre><code>curl http://127.0.0.1:1337/\n</code></pre> <p>Access the API:</p> <pre><code>curl http://127.0.0.1:1338/api/\n</code></pre>"},{"location":"intro/quick-start-k8s/#troubleshooting","title":"Troubleshooting","text":"<p>If there are problems loading the configuration, verify that the Pod has the latest configuration available:</p> <pre><code>kubectl exec $POD_NAME -- cat /etc/kache/config.yml </code></pre>"},{"location":"intro/quick-start/","title":"Quick Start","text":"<p>The following describes how to run kache locally with Docker.</p>"},{"location":"intro/quick-start/#set-up-a-docker-compose","title":"Set up a docker-compose","text":"<p>Create and define a docker-compose.yml and define a kache service that uses the official Kache image:</p> <pre><code>services:\nkache:\n# Use the `main` tag for the latest development image \n# or `latest` tag for the latest stable version.\nimage: kacheio/kache:main\ncontainer_name: kache\n# Start the container with the mounted config file.\ncommand:\n- \"-config.file=/etc/kache/kache.sample.yml\"\n# Expose ports that are configured in the kache config file.\nports:\n- \"80:80\"\n- \"8080:8080\"\n- \"1337:1337\"\n- \"1338:1338\"\n# Mount the config file.\nvolumes:\n- \"./../kache.sample.yml:/etc/kache/kache.sample.yml\"\n# Use redis as distributed remote caching backend.\nredis:\nimage: \"redis:alpine\"\n</code></pre> <p>That's all you need to run Kache with Redis as a distributed caching backend. </p>"},{"location":"intro/quick-start/#run-kache","title":"Run kache","text":"<p>Now start Kache with the following command:</p> <pre><code>docker-compose -f cloud/docker/docker-compose.yml up \n</code></pre>"},{"location":"intro/quick-start/#access-kache","title":"Access kache","text":"<p>You can now access the service under <code>http://localhost:8080/</code> and the API under <code>http://localhost:1338/api/cache/keys</code> which returns all the keys currentlz in the cache.</p>"},{"location":"reference/","title":"Reference","text":""},{"location":"setup/","title":"Setup","text":""}]}